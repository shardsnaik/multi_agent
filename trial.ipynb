{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c669e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11245338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--Salesforce--blip-image-captioning-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8a8fc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is this image of a restaurant?\n"
     ]
    }
   ],
   "source": [
    "img_url = 'C:\\\\Users\\\\Admin\\\\Downloads\\\\resturent.jpg' \n",
    "# raw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n",
    "raw_image = Image.open(img_url).convert('RGB')\n",
    "# conditional image captioning\n",
    "text = input('Enter the text: ').lower()\n",
    "inputs = processor(raw_image, text, return_tensors=\"pt\")\n",
    "out = model.generate(**inputs)\n",
    "print(processor.decode(out[0], skip_special_tokens=True))\n",
    "# >>> a photography of a woman and her dog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84710544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[30522,  2054,  2003,  2023,  3746,  1997,  1037,  4825,  1029,   102]])\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3487302b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Architecture if txt input -> functin 1 if only image function 1 else if input contains both fucntion 2 it makes easliy understandability and durability of code ( if  Objects are created its beter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26de6075",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "# pipe = pipeline(\n",
    "#     'image-to-text',\n",
    "#     model=\"Salesforce/blip-image-captioning-base\",\n",
    "#     device='cpu',\n",
    "#     torch_dtype='torch.bfloat16' if torch.cuda.is_available() else 'float32'\n",
    "\n",
    "# )\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "def image_to_base64(image_path:str)-> str:\n",
    "    '''\n",
    "    Function decode the image\n",
    "    Args: Image_path\n",
    "    Returns:\n",
    "      Base64 decode image\n",
    "    '''\n",
    "    with open(image_path, 'rb') as img:\n",
    "        image = img.read().decode('utf-8')\n",
    "        decoded_imge = base64.b64encode(image)\n",
    "        # return base64.b64encode(img.read()).decode('utf-8')\n",
    "        return decoded_imge\n",
    "\n",
    "def run_agent(image_src: str = None, text_input: str= None)-> str:\n",
    "    '''\n",
    "    Input: \n",
    "    The fucntion that takes image and text as input \n",
    "    Return:\n",
    "        Model Generated Text\n",
    "    '''\n",
    "    content = []\n",
    "    if text_input:\n",
    "        content.append({'type':'text', 'text': text_input})\n",
    "    if image_src:\n",
    "        decoded_image = image_to_base64(image_path=image_src)\n",
    "        content.append({\n",
    "            'type': 'image_url',\n",
    "            'image_url':{\n",
    "                \"url\": f\"data:image/jpeg;base64,{decoded_image}\"\n",
    "\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    response= client.chat.completions.create(\n",
    "        model = \"gpt-4.1\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": content}\n",
    "        ],\n",
    "        max_tokens=300\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d4604c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Entropy** in physics is a measure of the disorder, randomness, or uncertainty within a physical system. It is a central concept in thermodynamics and statistical mechanics.\n",
      "\n",
      "### Key Points\n",
      "\n",
      "- **Thermodynamics:**  \n",
      "  Entropy quantifies the amount of energy in a system that is unavailable for doing work. When energy is transformed (like heat into work), some energy becomes less useful, and entropy increases. According to the *Second Law of Thermodynamics*, the total entropy of an isolated system can never decrease; it tends to increase over time, leading to irreversibility in natural processes.\n",
      "\n",
      "- **Statistical Interpretation:**  \n",
      "  From a microscopic perspective (statistical mechanics), entropy measures the number of possible microscopic arrangements (microstates) that correspond to the same macroscopic state. More microstates mean higher entropy. The famous formula is:\n",
      "  \\[\n",
      "  S = k_B \\ln W\n",
      "  \\]\n",
      "  where \\( S \\) is entropy, \\( k_B \\) is Boltzmann's constant, and \\( W \\) is the number of microstates.\n",
      "\n",
      "- **Everyday Example:**  \n",
      "  If you mix hot and cold water, the temperature evens out, and the overall entropy increases. It never spontaneously decreases (like all cold water becoming hot, and all hot water cold, without external work).\n",
      "\n",
      "### Summary\n",
      "\n",
      "**Entropy** is a quantitative way to express the spread or randomness of energy and matter in a system. It underpins why certain processes are irreversible\n"
     ]
    }
   ],
   "source": [
    "# Text only\n",
    "print(run_agent(text_input=\"Explain the concept of entropy in physics.\"))\n",
    "\n",
    "# Image only\n",
    "# print(run_agent(image_path=\"sample.jpg\"))\n",
    "\n",
    "# Text + Image\n",
    "# print(run_agent(text_input=\"What is happening in this image?\", image_path=\"sample.jpg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8851e0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
