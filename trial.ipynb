{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c669e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11245338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--Salesforce--blip-image-captioning-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8a8fc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is this image of a restaurant?\n"
     ]
    }
   ],
   "source": [
    "img_url = 'C:\\\\Users\\\\Admin\\\\Downloads\\\\resturent.jpg' \n",
    "# raw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n",
    "raw_image = Image.open(img_url).convert('RGB')\n",
    "# conditional image captioning\n",
    "text = input('Enter the text: ').lower()\n",
    "inputs = processor(raw_image, text, return_tensors=\"pt\")\n",
    "out = model.generate(**inputs)\n",
    "print(processor.decode(out[0], skip_special_tokens=True))\n",
    "# >>> a photography of a woman and her dog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84710544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[30522,  2054,  2003,  2023,  3746,  1997,  1037,  4825,  1029,   102]])\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3487302b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Architecture if txt input -> functin 1 if only image function 1 else if input contains both fucntion 2 it makes easliy understandability and durability of code ( if  Objects are created its beter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26de6075",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "# pipe = pipeline(\n",
    "#     'image-to-text',\n",
    "#     model=\"Salesforce/blip-image-captioning-base\",\n",
    "#     device='cpu',\n",
    "#     torch_dtype='torch.bfloat16' if torch.cuda.is_available() else 'float32'\n",
    "\n",
    "# )\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "class Multiagent:\n",
    "        def image_to_base64(image_path:str)-> str:\n",
    "            '''\n",
    "            Function to decode the image\n",
    "                Args: \n",
    "                    image_path (str): Path to the image file\n",
    "                Returns:\n",
    "                    str: Base64 encoded image\n",
    "            '''\n",
    "            with open(image_path, 'rb') as img:\n",
    "                image_bytes = img.read()\n",
    "                decoded_imge = base64.b64encode(image_bytes).decode('utf-8')\n",
    "                # return base64.b64encode(img.read()).decode('utf-8')\n",
    "                return decoded_imge\n",
    "\n",
    "        def run_agent(self, image_src: str = None, text_input: str= None)-> str:\n",
    "            '''\n",
    "            Input: \n",
    "            The fucntion that takes image and text as input \n",
    "            Return:\n",
    "                Model Generated Text\n",
    "            '''\n",
    "            content = []\n",
    "            if not text_input and not image_src:\n",
    "                 return 'Please proivde either text input or image input'\n",
    "            if text_input:\n",
    "                content.append({'type':'text', 'text': text_input})\n",
    "            if image_src:\n",
    "                try:\n",
    "                     decoded_image = self.image_to_base64(image_path=image_src)\n",
    "                     content.append({\n",
    "                    'type': 'image_url',\n",
    "                    'image_url':{\n",
    "                        \"url\": f\"data:image/jpeg;base64,{decoded_image}\"\n",
    "        \n",
    "                    }\n",
    "                })\n",
    "                except Exception as e:\n",
    "                     return f'Error processing image: {str(e)}'\n",
    "            # Adding user messages to memory \n",
    "            self.add_to_memory('user', content)\n",
    "            \n",
    "            response= client.chat.completions.create(\n",
    "                model = \"gpt-4.1\",\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": content}\n",
    "                ],\n",
    "                max_tokens=300\n",
    "            )\n",
    "            assistant_response = response.choices[0].message.content\n",
    "            self.add_to_memory('assitant', assistant_response)\n",
    "            \n",
    "            return assistant_response\n",
    "        \n",
    "        def add_to_memory(self, role:str, content):\n",
    "             ''''\n",
    "             add message to conversation memory\n",
    "\n",
    "             Args:\n",
    "                role(str): 'user' or 'assistant'\n",
    "                content: Generated messages or user input (query)\n",
    "             '''\n",
    "             self.conversation_history = []\n",
    "             self.max_history = 50\n",
    "             messages = {'role': role, 'content': content}\n",
    "             self.conversation_history.append(messages)\n",
    "             \n",
    "             if len(self.conversation_history)> self.max_history:\n",
    "                  if self.conversation_history[0].get('role') == 'system':\n",
    "                       self.conversation_history = [self.conversation_history[0] ] + self.conversation_history[-(self.max_history-1):]\n",
    "                  else:\n",
    "                       self.conversation_history = self.conversation_history[-self.max_history:]\n",
    "        def set_system_message(self, system_messages:str):\n",
    "             \"\"\"\n",
    "        Set or update the system message\n",
    "        \n",
    "        Args:\n",
    "            system_message (str): System prompt to guide the assistant's behavior\n",
    "        \"\"\"\n",
    "             if self.conversation_history and self.conversation_history[0].get(\"role\") == \"system\":\n",
    "                  self.conversation_history.pop(0)\n",
    "        \n",
    "        # Add new system message at the beginning\n",
    "             self.conversation_history.insert(0, {\"role\": \"system\", \"content\": system_messages})\n",
    "\n",
    "        def get_conversation_history(self):\n",
    "             '''\n",
    "             Get the current conversation history\n",
    "\n",
    "             Returns: \n",
    "                 list: List of conversation messages\n",
    "             '''\n",
    "             return self.conversation_history\n",
    "        def clear_history(self):\n",
    "             '''\n",
    "             Clearing the conversation history \n",
    "             '''\n",
    "             system_msg = None\n",
    "             if self.conversation_history and self.conversation_history[0].get('role') == 'system':\n",
    "                  system_msg = self.conversation_history[0]\n",
    "             self.conversation_history = []\n",
    "\n",
    "             if system_msg:\n",
    "                  self.conversation_history.append(system_msg)\n",
    "\n",
    "        def save_conversation(self, filename: str):\n",
    "             ''' \n",
    "             Function which saves the conversation history\n",
    "             \n",
    "             Args:\n",
    "                  filename (str): Path to save the conversation\n",
    "            '''\n",
    "             import json, datetime\n",
    "             chat_name = datetime.datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "             with open(chat_name, 'w', encoding='utf-8') as f:\n",
    "                  json.dump(self.conversation_history, f, indent=2)\n",
    "                  print(f'Conversation History saved to file: {chat_name}')             \n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d4604c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image features Iron Man, a popular Marvel Comics superhero, in his iconic red and gold armor. He is depicted with his hand extended forward, palm open, with the repulsor in his palm glowing brightly, suggesting he is about to fire a repulsor blast. The image also includes a cracked, shattered glass effect in the foreground, adding a dramatic and action-packed feeling to the scene. The background is dark, making the glowing lights from the suit stand out even more.\n"
     ]
    }
   ],
   "source": [
    "# Text only\n",
    "# print(run_agent(text_input=\"Explain the concept of entropy in physics.\"))\n",
    "\n",
    "# Image only\n",
    "print(run_agent(image_src=\"C:\\\\Users\\\\Admin\\\\OneDrive\\\\Pictures\\\\download.jpeg\"))\n",
    "\n",
    "# Text + Image\n",
    "# print(run_agent(text_input=\"What is happening in this image?\", image_path=\"sample.jpg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8851e0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye\n"
     ]
    }
   ],
   "source": [
    "agent = Multiagent()\n",
    "while True:\n",
    "    user_input = input('\\nGive Text Input or Image or both but while giving image input mention image:\"Your Image\"\\nYou:').strip()\n",
    "    image_path = None\n",
    "    if 'image' in user_input.lower():\n",
    "        parts = user_input.split(':')[-1]\n",
    "        print(parts)\n",
    "        if len(parts) > 1:\n",
    "                image_path = parts[1].strip()\n",
    "        # user_input = input(\"Enter your question about the image: \").strip()\n",
    "        \n",
    "        # Get response from chatbot\n",
    "        response = agent.run_agent(image_src=image_path, text_input=user_input)\n",
    "        print(f\"\\nAssistant: {response}\")\n",
    "        \n",
    "        # Show memory usage\n",
    "        print(f\"[Memory: {len(agent.conversation_history)} messages]\")\n",
    "\n",
    "    if user_input.lower() in ['quit', 'exit', 'bye']:\n",
    "        print(\"Goodbye\")\n",
    "        break\n",
    "    elif user_input.lower()  == 'clear':\n",
    "        agent.clear_history()\n",
    "        print('History cleared')\n",
    "        continue\n",
    "    elif user_input.lower().startswith('save '):\n",
    "        filename = user_input[5:].strip()\n",
    "        agent.save_conversation()\n",
    "        continue\n",
    "    elif user_input.lower().startswith('load '):\n",
    "        filename = user_input[5:].strip()\n",
    "        agent.get_conversation_history()\n",
    "        continue\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d704ce83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
